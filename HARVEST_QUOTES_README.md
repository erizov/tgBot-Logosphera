# Инструкция по сбору цитат из различных источников

Этот набор скриптов позволяет собирать английские и русские цитаты из различных источников, объединять их, дедуплицировать и импортировать в PostgreSQL.

## Установка зависимостей

```bash
pip install requests beautifulsoup4 tqdm
```

Или используйте существующий `requirements.txt`:

```bash
pip install -r requirements.txt
```

## Использование

### 1. Сбор цитат с Quotable API

```bash
python harvest_quotable.py
```

Создаст файл `quotable.json` с цитатами из Quotable API.

**Особенности:**
- Использует официальный API Quotable.io
- Автоматически проходит по всем страницам (около 15 страниц)
- Применяет строгие фильтры
- Прогресс-бар показывает процесс
- **Доступно:** ~2000 цитат после фильтрации (из 2127 в API)
- Исправлена логика пагинации для обработки всех страниц

### 2. Сбор цитат с ZenQuotes API

```bash
python harvest_zenquotes.py
```

Создаст файл `zenquotes.json` с цитатами из ZenQuotes API.

**Особенности:**
- Использует API ZenQuotes.io
- Дедупликация по тексту
- **ОБЯЗАТЕЛЬНАЯ** задержка 1 секунда между запросами (требование API)
- По умолчанию собирает до 5000 цитат

**Настройка количества:**
```python
# В файле harvest_zenquotes.py измените:
harvest_zenquotes(max_quotes=1000)  # Вместо 5000
```

### 3. Сбор цитат с Goodreads (веб-скрапинг)

```bash
python harvest_goodreads.py
```

Создаст файл `goodreads.json` с цитатами с Goodreads.

**⚠️ ВАЖНО:**
- Использует веб-скрапинг (может быть заблокирован)
- **ОБЯЗАТЕЛЬНАЯ** задержка 10 секунд между запросами
- По умолчанию собирает с 50 страниц (можно изменить)
- **Проблемы с доступом:** Если возникают таймауты или ошибки подключения:
  - Goodreads может быть заблокирован в некоторых странах (например, Россия)
  - **Решение:** Используйте VPN для обхода блокировки
  - Скрипт автоматически повторяет попытки (3 раза) с увеличенным таймаутом (60s)

**Настройка количества страниц:**
```python
# В файле harvest_goodreads.py измените:
harvest_goodreads(max_pages=20)  # Вместо 50
```

### 4. Сбор цитат с BrainyQuote (веб-скрапинг)

```bash
python harvest_brainyquote.py
```

Создаст файл `brainyquote.json` с цитатами с BrainyQuote.

**⚠️ ВАЖНО:**
- Использует веб-скрапинг (может быть заблокирован)
- **ОБЯЗАТЕЛЬНАЯ** задержка 15 секунд между запросами
- Собирает цитаты по различным темам

**Настройка тем:**
```python
# В файле harvest_brainyquote.py измените:
topics = ["motivational", "wisdom", "success"]  # Добавьте свои темы
harvest_brainyquote(topics=topics)
```

### 5. Объединение всех цитат

```bash
python merge_quotes.py
```

Объединит все JSON файлы (английские: `quotable.json`, `zenquotes.json`, `goodreads.json`, `brainyquote.json`; русские: `citaty_net.json`, `aphorizm_ru.json`, `anecdot_ru.json`, `wikiquote_ru.json`) в:
- `ALL_QUOTES.json` - объединенный JSON файл
- `ALL_QUOTES.txt` - текстовый файл для чтения

**Особенности:**
- Автоматическая дедупликация по тексту
- Исключает дубликаты между источниками
- Формат TXT: `текст — автор`

**Настройка:**
```python
# В файле merge_quotes.py можно изменить:
merge_quotes(
    input_pattern="harvest_*.json",  # Паттерн для поиска файлов
    output_json="MERGED_QUOTES.json",
    output_txt="MERGED_QUOTES.txt"
)
```

### 6. Сбор цитат с русских сайтов

#### 6.1. Citaty.net

```bash
python harvest_citaty_net.py
```

Создаст файл `citaty_net.json` с цитатами с Citaty.net.

**⚠️ ВАЖНО:**
- Использует веб-скрапинг
- **ОБЯЗАТЕЛЬНАЯ** задержка 5 секунд между запросами
- По умолчанию собирает с 20 страниц

#### 6.1.1. Citaty.info

```bash
python harvest_citaty_info.py
```

Создаст файл `citaty_info.json` с цитатами с Citaty.info.

**⚠️ ВАЖНО:**
- Использует веб-скрапинг
- **ОБЯЗАТЕЛЬНАЯ** задержка 5 секунд между запросами
- По умолчанию собирает с 20 страниц
- Проверка доступности сайта перед началом работы

**Настройка количества страниц:**
```python
# В файле harvest_citaty_net.py измените:
harvest_citaty_net(max_pages=10)  # Вместо 20
```

#### 6.2. Aphorizm.ru

```bash
python harvest_aphorizm_ru.py
```

Создаст файл `aphorizm_ru.json` с цитатами с Aphorizm.ru.

**⚠️ ВАЖНО:**
- Использует веб-скрапинг
- **ОБЯЗАТЕЛЬНАЯ** задержка 5 секунд между запросами
- По умолчанию собирает с 20 страниц
- **Проблемы:** Сайт может быть недоступен или заблокирован (ошибки подключения)

**Настройка количества страниц:**
```python
# В файле harvest_aphorizm_ru.py измените:
harvest_aphorizm_ru(max_pages=10)  # Вместо 20
```

#### 6.3. Anecdot.ru/aphorizm

```bash
python harvest_anecdot_ru.py
```

Создаст файл `anecdot_ru.json` с цитатами с Anecdot.ru/aphorizm.

**⚠️ ВАЖНО:**
- Использует веб-скрапинг
- **ОБЯЗАТЕЛЬНАЯ** задержка 5 секунд между запросами
- По умолчанию собирает с 20 страниц
- **Проверка доступности:** Скрипт автоматически проверяет доступность сайта перед началом работы
- **Проблемы:** Сайт может быть недоступен или заблокирован
  - Если сайт недоступен, скрипт сразу сообщит об этом и сохранит пустой файл
  - Пробует альтернативные URL (HTTP, с www и без)
  - Не тратит время на попытки подключения, если сайт недоступен

**Настройка количества страниц:**
```python
# В файле harvest_anecdot_ru.py измените:
harvest_anecdot_ru(max_pages=10)  # Вместо 20
```

#### 6.4. Wikiquote (русский)

```bash
python harvest_wikiquote_ru.py
```

Создаст файл `wikiquote_ru.json` с цитатами с Wikiquote (русский).

**⚠️ ВАЖНО:**
- Использует веб-скрапинг
- **ОБЯЗАТЕЛЬНАЯ** задержка 5 секунд между запросами (увеличена для избежания 403)
- Собирает цитаты по списку авторов
- **Проблемы:** Wikiquote имеет строгие ограничения на частоту запросов
  - При ошибках 403 (Too Many Requests) скрипт автоматически ждет 30 секунд
  - Если ошибки продолжаются, увеличьте задержку в коде

**Настройка авторов:**
```python
# В файле harvest_wikiquote_ru.py измените:
authors = ["Лев Толстой", "Фёдор Достоевский", "Антон Чехов"]
harvest_wikiquote_ru(authors=authors)
```

#### 6.5. Локальные doc/docx файлы (русский)

```bash
python harvest_doc_files.py
```

Создаст файл `doc_files.json` с цитатами из локальных файлов.

**Особенности:**
- Ищет все файлы в текущей папке, начинающиеся с "aph" (например, `aphDop2.doc`, `aphDop3.docx`)
- Поддерживает форматы `.doc` (старый формат) и `.docx` (современный формат)
- Автоматически определяет кодировку для `.doc` файлов (UTF-8, CP1251, Windows-1251, CP866, Latin-1)
- Парсит только текст до слова "Here" (регистронезависимо)
- Извлекает только цитаты из 1-5 предложений
- Автоматически извлекает автора из текста (если указан через "—" или "–")
- Применяет строгие фильтры валидации
- Дедуплицирует цитаты по тексту

**Требования:**
- Для `.docx` файлов требуется библиотека `python-docx` (уже в requirements.txt)
- Для `.doc` файлов скрипт пытается прочитать их как текст с различными кодировками
- **⚠️ ВАЖНО:** Старые `.doc` файлы (бинарный формат OLE2) не могут быть прочитаны напрямую
  - Если файл в бинарном формате, скрипт выдаст предупреждение и пропустит его
  - **Решения для чтения бинарных .doc файлов:**
    1. **Рекомендуется:** Конвертируйте `.doc` файлы в `.docx` через Microsoft Word или LibreOffice
    2. **Используйте antiword** (внешняя утилита):
       - Windows: Скачайте с https://www.winfield.demon.nl/
       - Linux: `sudo apt-get install antiword` или `sudo yum install antiword`
       - Скрипт автоматически обнаружит и использует antiword если он установлен
    3. **Используйте textract** (может иметь проблемы совместимости):
       ```bash
       # Требует pip < 24.1 из-за проблем с метаданными библиотеки
       pip install "pip<24.1" --upgrade
       pip install textract
       ```
       ⚠️ **Примечание:** textract имеет проблемы совместимости с pip>=24.1

**Настройка:**
```python
# В файле harvest_doc_files.py измените:
harvest_doc_files(
    folder_path="./quotes",  # Путь к папке с файлами
    output_file="my_quotes.json"  # Имя выходного файла
)
```

**Формат файлов:**
- Файлы должны начинаться с "aph" (например, `aphDop2.doc`, `aphQuotes.docx`)
- Скрипт парсит весь текст до слова "Here" (регистронезависимо)
- Цитаты должны быть на русском языке
- Автор может быть указан через "—" или "–" в конце цитаты

### 7. Импорт в PostgreSQL

```bash
python import_to_postgres.py
```

Импортирует цитаты из `ALL_QUOTES.json` в таблицу `quotations` PostgreSQL.

**Опции:**
```bash
# Очистить существующие цитаты перед импортом
python import_to_postgres.py --clear

# Или короткая форма
python import_to_postgres.py -c

# Указать другой файл
python import_to_postgres.py --file custom_quotes.json
```

**Особенности:**
- Автоматически создает таблицу если не существует
- Дедупликация по `(text_original, language_original)`
- Применяет строгие фильтры перед импортом
- Показывает статистику импорта

## Автоматизированный пайплайн (рекомендуется)

Для автоматизации всего процесса используйте главный скрипт:

```bash
python harvest_pipeline.py
```

Этот скрипт автоматически:
1. Запускает все `harvest_*.py` скрипты по очереди
2. Пропускает скрипты с приемлемыми ошибками (сайт недоступен и т.д.)
3. Объединяет все собранные цитаты
4. Импортирует в PostgreSQL
5. Выполняет дедупликацию

**Опции:**
```bash
# Показать только статистику из БД (без загрузки)
python harvest_pipeline.py --stats

# Пропустить этап сбора (если уже собрали)
python harvest_pipeline.py --skip-harvest

# Пропустить объединение
python harvest_pipeline.py --skip-merge

# Пропустить импорт
python harvest_pipeline.py --skip-import

# Очистить БД перед импортом
python harvest_pipeline.py --clear

# Комбинации
python harvest_pipeline.py --skip-harvest --clear  # Только merge + import с очисткой
```

**Статистика:**
После импорта автоматически показывается:
- Общее количество цитат в БД
- Количество цитат по языкам (EN, RU)
- Общее количество авторов
- Количество авторов по языкам (EN, RU)
- Топ авторов

Для просмотра только статистики без загрузки:
```bash
python harvest_pipeline.py --stats
# или
python import_to_postgres.py --stats
```

**Особенности:**
- Автоматически обрабатывает ошибки подключения
- Продолжает работу даже если некоторые источники недоступны
- Детальное логирование в консоль и файл `harvest_pipeline.log`
- Статистика по каждому этапу
- Таймаут 1 час на каждый harvest скрипт

## Полный процесс сбора (ручной)

### Вариант 1: Последовательный запуск

```bash
# 1. Собираем английские цитаты
python harvest_quotable.py
python harvest_zenquotes.py
python harvest_goodreads.py
python harvest_brainyquote.py

# 2. Собираем русские цитаты
python harvest_citaty_net.py
python harvest_aphorizm_ru.py
python harvest_anecdot_ru.py
python harvest_wikiquote_ru.py
python harvest_doc_files.py

# 3. Объединяем все
python merge_quotes.py

# 4. Импортируем в БД
python import_to_postgres.py --clear
```

### Вариант 1.1: Только английские цитаты

```bash
# 1. Собираем английские цитаты
python harvest_quotable.py      # ~2000 цитат (API, быстро)
python harvest_zenquotes.py      # До 5000 цитат (API, медленно)
python harvest_goodreads.py     # Много цитат (веб-скрапинг)
python harvest_brainyquote.py    # Много цитат (веб-скрапинг)

# 2. Объединяем
python merge_quotes.py

# 3. Импортируем в БД
python import_to_postgres.py --clear
```

**Примечание:** Quotable API теперь собирает все доступные цитаты (~2000 после фильтрации). Для еще большего количества используйте ZenQuotes, Goodreads или BrainyQuote.

### Вариант 1.2: Только русские цитаты

```bash
# 1. Собираем русские цитаты
python harvest_citaty_net.py
python harvest_aphorizm_ru.py
python harvest_anecdot_ru.py
python harvest_wikiquote_ru.py
python harvest_doc_files.py

# 2. Объединяем
python merge_quotes.py

# 3. Импортируем в БД
python import_to_postgres.py --clear
```

### Вариант 2: Использование основного скрипта

Основной скрипт `load_quotations.py` уже интегрирует многие из этих источников:

```bash
python load_quotations.py
```

## Строгие фильтры

Все скрипты применяют одинаковые строгие фильтры:

- ❌ **Нет цифр** (арабские и римские)
- ❌ **Нет имен людей** (два подряд заглавных слова)
- ❌ **Нет адресов и мест** (street, avenue, москва, лондон и т.д.)
- ❌ **Нет названий книг/фильмов** (в кавычках с заглавными буквами)
- ❌ **Нет URL и email**
- ❌ **Нет дат** (названия месяцев)
- ❌ **Нет театральных ссылок** (act, scene, page, chapter)
- ❌ **Нет спам-паттернов** (повторяющиеся символы)

## Формат данных

Все JSON файлы используют единый формат:

```json
{
  "text": "The only way to do great work is to love what you do.",
  "author": "Steve Jobs",
  "source": "quotable",
  "lang": "en"
}
```

## Рекомендации

1. **Начните с API источников** (Quotable, ZenQuotes) - они быстрее и надежнее
   - **Quotable API:** ~2000 цитат после фильтрации (из 2127 доступных)
   - **ZenQuotes API:** до 5000 цитат (требует задержку 1 секунда между запросами)
2. **Используйте веб-скрапинг осторожно** - соблюдайте задержки и не злоупотребляйте
3. **Проверяйте результаты** - просмотрите созданные JSON файлы перед импортом
4. **Дедупликация** - `merge_quotes.py` автоматически удаляет дубликаты
5. **Тестирование** - сначала соберите небольшое количество цитат для проверки

## Устранение проблем

### Ошибка подключения к API
- Проверьте интернет-соединение
- Увеличьте timeout в скриптах
- Некоторые API могут быть временно недоступны

### Ошибка веб-скрапинга
- Увеличьте задержки между запросами
- Проверьте User-Agent заголовки
- Некоторые сайты могут блокировать скрапинг
- **Геоблокировка (Goodreads/BrainyQuote):**
  - Если возникают таймауты или `ConnectionError`, это может быть из-за блокировки доступа из вашей страны
  - **Решение:** Используйте VPN для обхода блокировки
  - Скрипт автоматически повторяет попытки (3 раза) с увеличенным таймаутом (60s)
  - Пример: Подключите VPN, затем запустите `python harvest_goodreads.py`
- **403 Too Many Requests (Wikiquote):**
  - Wikiquote имеет строгие ограничения на частоту запросов
  - Скрипт автоматически ждет 30 секунд при ошибке 403
  - Если ошибки продолжаются, увеличьте задержку в коде (измените `time.sleep(5)` на большее значение)
- **Сайты недоступны (Aphorizm.ru, Anecdot.ru):**
  - Некоторые русские сайты могут быть недоступны или заблокированы
  - Если возникают ошибки подключения, попробуйте позже или используйте другие источники
  - Скрипт продолжит работу даже если некоторые источники недоступны

### Ошибка импорта в PostgreSQL
- Проверьте переменную окружения `DB_URL` в `.env`
- Убедитесь, что PostgreSQL запущен
- Проверьте права доступа к БД

## Примеры использования

### Сбор только из API источников (английские)

```bash
python harvest_quotable.py
python harvest_zenquotes.py
python merge_quotes.py
python import_to_postgres.py
```

### Сбор только из веб-скрапинга (русские)

```bash
python harvest_citaty_net.py
python harvest_aphorizm_ru.py
python harvest_anecdot_ru.py
python harvest_wikiquote_ru.py
python harvest_doc_files.py
python merge_quotes.py
python import_to_postgres.py
```

### Быстрый тест (малое количество)

```python
# В каждом скрипте измените параметры:
harvest_zenquotes(max_quotes=100)  # Вместо 5000
harvest_goodreads(max_pages=5)     # Вместо 50
```

## Лицензия и использование

Все скрипты используют публичные API и веб-скрапинг в образовательных целях. Соблюдайте условия использования каждого источника и не злоупотребляйте запросами.
